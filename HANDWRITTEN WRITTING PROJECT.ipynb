{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HANDWRITTEN WRITTING PROJECT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTING LIBRARIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from keras.preprocessing.image import ImageDataGenerator  \n",
    "# ImageDataGeneraor is used for generating the images\n",
    "# the colors of images ranges from 0-255 (works like feature scaling)\n",
    "# but we will take it in the 0/1 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.keras.utils as tku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Part 1 : Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing The Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37340 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# we will apply diffrent transformations on the image \n",
    "# rescale : we will standerise  value in standerise form \n",
    "# share_range : we will move image closckwise in particular angle \n",
    "# zomm_range : we will zoom the image \n",
    "# horizontal_flip : we will set our image horizontally \n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255 ,\n",
    "                                   shear_range=0.2 ,\n",
    "                                   zoom_range=0.2 ,\n",
    "                                   horizontal_flip=True )\n",
    "\n",
    "# we will import the dataset from our file directory directly \n",
    "# we are not using pandas here for importing \n",
    "\n",
    "# target_size : All images will have the diffrent size we will set them in the particular size \n",
    "# batch_size : we will not take all images at once we will divide all dataset images in batches of 32 \n",
    "# class_mode : In the training set folder we have further 2 subfolders ( 2 categories)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('C:\\\\Users\\\\swapn\\\\Machine learning projects\\\\PREPINSTA\\\\DATASET\\\\HANDWRITTEN WRITTING PROJECT MNIST\\\\training_set',\n",
    "                                                 target_size=(28, 28),\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "                                                 \n",
    "                                                 \n",
    "\n",
    " # it will tell us how many images present and preset folders "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing The Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4660 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# we will apply diffrent transformations on the image \n",
    "# rescale : we will standerise  value in standerise form \n",
    "# share_range : we will move image closckwise in particular angle \n",
    "# zomm_range : we will zoom the image \n",
    "# horizontal_flip : we will set our image horizontally\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "# we will import the dataset from our file directory directly \n",
    "# we are not using pandas here for importing \n",
    "\n",
    "# target_size : All images will have the diffrent size we will set them in the particular size \n",
    "# batch_size : we will not take all images at once we will divide all dataset images in batches of 32 \n",
    "# class_mode : In the training set folder we have further 2 subfolders ( 2 categories)\n",
    "\n",
    "test_set = train_datagen.flow_from_directory('C:\\\\Users\\\\swapn\\\\Machine learning projects\\\\PREPINSTA\\\\DATASET\\\\HANDWRITTEN WRITTING PROJECT MNIST\\\\test_set',\n",
    "                                             target_size=(28, 28),\n",
    "                                             batch_size=32,\n",
    "                                             class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 : BUILDING THE CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "# WE HAVE CREATED THE INITIALIZATION FOR THE NEURONS WE ARE GOING TO USE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters=32 : WE WILL APPLY NO.OF FILTERS ON THE INPUT IMAGE \n",
    "# EACH FILTER IS USED FOR DETECTING THE SPECIFIC FEATURE FROM THE IMAGE \n",
    "\n",
    "# kernel_size=3 : SPECIFY THE HEIGHT OF CONVOLUTIONAL WINDOW  , HERE 3 : THE CONVOLUTIONAL KERNAL WILL CREATE THE 3* 3 MATRIX FOR EACH IMAGE \n",
    "\n",
    "# activation = \"relu\" : RECTIFIED LINEAR UNIT # IT WILL RETURN THE IMPUT IMAGE IS O/1 \n",
    "# FOR INCREASING THE NON LINEARITY OF THE IMAGE \n",
    "\n",
    "# input_shape = [64 , 64 , 3] : WE WILL SPECIFY THE SIZE ( HEIGHT , WIDTH , CHANNELS )\n",
    "# CHANNELS : NO.OF COLUR CHANNNEL \n",
    "\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32 , kernel_size=3 , activation = \"relu\" , input_shape = [28 , 28 , 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2 , strides = 2 ))\n",
    "\n",
    "# pool_size = 2 : we will take here 2*2 window from the above created window \n",
    "# strides = 2  :  we will tell how our window will move it will move 2*2 in the metrix in vertically and horizontaly \n",
    "\n",
    "# we will find the maximum size from the pooling created metix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding A Second Convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have created the metrix in after pooling \n",
    "# we will identify the max_size from the polling matrix \n",
    "\n",
    "# we will use the 2 layers neural network for the better prediction \n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32 , kernel_size=3 , activation = \"relu\" )) \n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2 , strides = 2 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Flattering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have created the 2 neurons layers but this neurons layers cant accept the values of images \n",
    "# so using flattering for this this will convert this values into the linear data points \n",
    "\n",
    "cnn.add(tf.keras.layers.Flatten())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Full Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally we will make the full connection with the neurons \n",
    "# units = 120 : cicles present in the neuronsl network (in hidden layer)\n",
    "# activation = \"relu\" we will use it \n",
    "\n",
    "# we will use the DENSE function for this making the connection \n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units = 64 , activation = \"relu\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will create the output layer now \n",
    "# unit = 10 : the output layer will hav 10 cicle as we know \n",
    "# activation = \" sigmoid\" # activation function is also used in the output layer also \n",
    "\n",
    "# only in the output layer the activation function will be sigmoid\n",
    "\n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 : Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = \" adam : used for predicting the weights for the input layer values(features )\n",
    "# loss = \"binary_crossentropy\" : WE NEED THE RESULT IN BINARY FORMAT # we will store this binary in all the neiurons \n",
    "# metrics = \"accuracy\" : for increasing the performance and the accuracy \n",
    "# we will compile the cnn \n",
    "\n",
    "# DATA IS BINARY SO WE USED BINARY CROSSENTROPY \n",
    "# IF THE DATA IS CATEGORICAL THEN WE MUST HAVE USED THE CATEGORICAL_CROSSENTROPY \n",
    "\n",
    "cnn.compile(optimizer = \"adam\" , loss = \"binary_crossentropy\" , metrics = [\"accuracy\"] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the CNN on the training set and evaluting the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1167/1167 [==============================] - 69s 58ms/step - loss: 0.1331 - accuracy: 0.7424 - val_loss: 0.0668 - val_accuracy: 0.8845\n",
      "Epoch 2/20\n",
      "1167/1167 [==============================] - 74s 64ms/step - loss: 0.0552 - accuracy: 0.9085 - val_loss: 0.0438 - val_accuracy: 0.9283\n",
      "Epoch 3/20\n",
      "1167/1167 [==============================] - 65s 56ms/step - loss: 0.0416 - accuracy: 0.9321 - val_loss: 0.0381 - val_accuracy: 0.9412\n",
      "Epoch 4/20\n",
      "1167/1167 [==============================] - 58s 49ms/step - loss: 0.0355 - accuracy: 0.9417 - val_loss: 0.0367 - val_accuracy: 0.9403\n",
      "Epoch 5/20\n",
      "1167/1167 [==============================] - 79s 68ms/step - loss: 0.0313 - accuracy: 0.9478 - val_loss: 0.0318 - val_accuracy: 0.9459\n",
      "Epoch 6/20\n",
      "1167/1167 [==============================] - 83s 71ms/step - loss: 0.0277 - accuracy: 0.9543 - val_loss: 0.0267 - val_accuracy: 0.9558\n",
      "Epoch 7/20\n",
      "1167/1167 [==============================] - 74s 63ms/step - loss: 0.0258 - accuracy: 0.9578 - val_loss: 0.0242 - val_accuracy: 0.9616\n",
      "Epoch 8/20\n",
      "1167/1167 [==============================] - 56s 48ms/step - loss: 0.0240 - accuracy: 0.9606 - val_loss: 0.0248 - val_accuracy: 0.9597\n",
      "Epoch 9/20\n",
      "1167/1167 [==============================] - 75s 64ms/step - loss: 0.0223 - accuracy: 0.9625 - val_loss: 0.0226 - val_accuracy: 0.9631\n",
      "Epoch 10/20\n",
      "1167/1167 [==============================] - 80s 68ms/step - loss: 0.0209 - accuracy: 0.9644 - val_loss: 0.0216 - val_accuracy: 0.9618\n",
      "Epoch 11/20\n",
      "1167/1167 [==============================] - 72s 62ms/step - loss: 0.0204 - accuracy: 0.9663 - val_loss: 0.0197 - val_accuracy: 0.9667\n",
      "Epoch 12/20\n",
      "1167/1167 [==============================] - 54s 47ms/step - loss: 0.0196 - accuracy: 0.9670 - val_loss: 0.0224 - val_accuracy: 0.9618\n",
      "Epoch 13/20\n",
      "1167/1167 [==============================] - 45s 38ms/step - loss: 0.0189 - accuracy: 0.9686 - val_loss: 0.0185 - val_accuracy: 0.9700\n",
      "Epoch 14/20\n",
      "1167/1167 [==============================] - 44s 38ms/step - loss: 0.0176 - accuracy: 0.9711 - val_loss: 0.0195 - val_accuracy: 0.9648\n",
      "Epoch 15/20\n",
      "1167/1167 [==============================] - 45s 39ms/step - loss: 0.0170 - accuracy: 0.9719 - val_loss: 0.0180 - val_accuracy: 0.9723\n",
      "Epoch 16/20\n",
      "1167/1167 [==============================] - 44s 38ms/step - loss: 0.0168 - accuracy: 0.9723 - val_loss: 0.0154 - val_accuracy: 0.9770\n",
      "Epoch 17/20\n",
      "1167/1167 [==============================] - 45s 38ms/step - loss: 0.0162 - accuracy: 0.9739 - val_loss: 0.0168 - val_accuracy: 0.9736\n",
      "Epoch 18/20\n",
      "1167/1167 [==============================] - 45s 38ms/step - loss: 0.0151 - accuracy: 0.9754 - val_loss: 0.0186 - val_accuracy: 0.9689\n",
      "Epoch 19/20\n",
      "1167/1167 [==============================] - 45s 39ms/step - loss: 0.0156 - accuracy: 0.9741 - val_loss: 0.0178 - val_accuracy: 0.9717\n",
      "Epoch 20/20\n",
      "1167/1167 [==============================] - 44s 38ms/step - loss: 0.0144 - accuracy: 0.9762 - val_loss: 0.0182 - val_accuracy: 0.9695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x240fdb2fd90>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOW WE WILL TRAIN OUR MODEL USING THE TRAINING SET DATA AND THE TESTING SET DATA \n",
    "\n",
    "# epochs = 20 : means we will train our model 20 times \n",
    "# in ann we have done this 120 times \n",
    "\n",
    "# x = training set : means we will takwe the traing set data \n",
    "# our model will learn from this \n",
    "\n",
    "# validation = test_set   # now it will try to comapre that with the testing data cat folder \n",
    "\n",
    "\n",
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAKING PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 468ms/step\n",
      "Prediction: Seven\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Load the image and preprocess it\n",
    "test_image = image.load_img(r'C:\\Users\\swapn\\Machine learning projects\\PREPINSTA\\DATASET\\HANDWRITTEN WRITTING PROJECT MNIST\\single_prediction\\img_28.jpg', target_size=(28, 28))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "results = (cnn.predict(test_image))\n",
    "\n",
    "# Get the index of the class with the highest probability\n",
    "predicted_class_index = np.argmax(results)\n",
    "\n",
    "# Decode the predicted class\n",
    "class_labels = ['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\n",
    "prediction = class_labels[predicted_class_index]\n",
    "\n",
    "print(\"Prediction:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+nxQyzyCOGN5HPRUUk/kKu3Wg6xY2f2y70m/t7XzPK8+a2dE38/LuIxng8e1Z9er/AAU8PeDtfvNQTxIYZLuMKba3nn8tXUg7iBkFiOPpXomo/GD4f+EI/snh/S0uZYXKBLK3WGNfU7iB79Ac1J8QvFy6l8Bxqd7Z/Zp9YRFit2blctuBGQCRtXPHY+lfMFFafh3Rp/EXiLT9Ith+9u51iBJwFBPJJ54Ayeh6V6/+0TqFvDL4f8OwDJtIDMT6KcIo9P4DXhtFaXh/XLvw3r1nrFiIzc2knmIJV3KexBGRwQSOoq14t8U33jLxBLrOoxW8VzKioy26sqYUYHBJP61h1//Z",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "file_path = r\"C:\\Users\\swapn\\Machine learning projects\\PREPINSTA\\DATASET\\HANDWRITTEN WRITTING PROJECT MNIST\\single_prediction\\img_28.jpg\"\n",
    "\n",
    "display(Image(filename=file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seven\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
